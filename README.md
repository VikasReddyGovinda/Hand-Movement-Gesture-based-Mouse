## Title of the Project
Hand Movement Gesture based Mouse using Machine Learning.

## About
<!--Detailed Description about the project-->
Hand movement gesture control is to design to operate with the help of a webcam. The Virtual Mouse application will be operational with the help of a webcam, as the webcam are responsible to capture the images in real time.A virtual input that can operate on all surface. The Virtual Mouse application will be operational on all surface and indoor environment, as long the users are facing the webcam while doing the motion gesture.
 
## Features
<!--List the features of the project as shown below-->
- Removes the requirement of having a physical mouse.
- Real time application. 
- Dynamic Gesture Recognition:
- User friendly application.
- Reduced Fatigue

## Requirements
<!--List the requirements of the project as shown below-->
* Operating System: Requires a 64-bit OS (Windows 10 or Ubuntu) for compatibility with deep learning frameworks.
* Development Environment: Python 3.6 or later is necessary for coding the sign language detection system.
* Deep Learning Frameworks: TensorFlow for model training, MediaPipe for hand gesture recognition.
* Image Processing Libraries: OpenCV is essential for efficient image processing and real-time hand gesture recognition.
* Version Control: Implementation of Git for collaborative development and effective code management.
* IDE: Use of VSCode as the Integrated Development Environment for coding, debugging, and version control integration.
* Additional Dependencies: Includes TensorFlow (versions 2.4.1), TensorFlow GPU, OpenCV, and Mediapipe for deep learning tasks.

## System Architecture
<!--Embed the system architecture diagram as shown below-->
<img width="248" alt="architecture" src="https://github.com/Vikasbunny21/Hand-Movement-Gesture-based-Mouse-using-Machine-Learning/assets/108391326/eb5f4102-99c7-4ff0-b0fa-90a2c67b4ea1">




## Output

<!--Embed the Output picture at respective places as shown below as shown below-->
#### Output1 - Computer Window with Mouse Cursor
<img width="180" alt="Cursor control" src="https://github.com/Vikasbunny21/Hand-Movement-Gesture-based-Mouse-using-Machine-Learning/assets/108391326/56906a21-088c-42ae-9dc0-25ac9c562398">


#### Output2 - Mouse Operation-Double Click
<img width="143" alt="double click" src="https://github.com/Vikasbunny21/Hand-Movement-Gesture-based-Mouse-using-Machine-Learning/assets/108391326/49b3ab2b-1ea0-4b59-b4db-24ff3acbf786">

Detection Accuracy: 95.7%
Note: These metrics can be customized based on your actual performance evaluations.


## Results and Impact
<!--Give the results and impact as shown below-->
The Hand Movement Gesture control system enhances accessibility for controlling mouse and providing a valuable tool for inclusive communication. The project's integration of computer vision and deep learning showcases its potential for intuitive and interactive human-computer interaction.

This project serves as a foundation for future developments in assistive technologies and contributes to creating a more inclusive and accessible digital environment.

## Articles published / References
1. Roshnee Matlani., Roshan Dadlani., Sharv Dumbre., Shruti Mishra., & Abha Tewari. (2021). Virtual Mouse Hand Gestures. In the International Conference on Technology Advancements and innovations (pp. 340-345). 
2. Steven Raj, N., Veeresh Gobbur, S., Praveen., Rahul Patil., & Veerendra Naik. (2020). Implementing Hand Gesture Mouse Using OpenCV. In the International Research Journal of Engineering and Technology (pp. 4257-4261). 
3. Krishnamoorthi, M., Gowtham, S., Sanjeevi, K., & Revanth Vishnu, R. (2022). Virtual mouse using YOLO. In the international conference on Innovative Computing, Intelligent Communication and Smart Electrical Systems (pp. 1-7).
4. L. Thomas, “Virtual mouse using hand gesture,” International Research Journal of Engineering and Technology (IRJET, vol. 5, no. 4, 2018.).
